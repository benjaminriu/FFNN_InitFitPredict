{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb971c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:36.233910Z",
     "start_time": "2022-06-29T13:17:35.486483Z"
    }
   },
   "outputs": [],
   "source": [
    "from feed_forward_neural_network import FeedForwardRegressor, FeedForwardClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e952d38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-27T14:57:34.743047Z",
     "start_time": "2022-06-27T14:57:34.740418Z"
    }
   },
   "source": [
    "#1 Simplest example\n",
    "#2 Comparison with Random Forests on a well-known dataset\n",
    "#3 Using provided architectures and hyper-parameters combinations\n",
    "#4 Using a custom architecture on an dataset of tensor observations (images from MNIST)\n",
    "#5 Using meta-learning\n",
    "#6 Using back-end class attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cf3014",
   "metadata": {},
   "source": [
    "# Simplest example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02926632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:37.332627Z",
     "start_time": "2022-06-29T13:17:37.329644Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from scipy.special import expit as logistic_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd8852",
   "metadata": {},
   "source": [
    "### Create data from a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddf3fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:38.870975Z",
     "start_time": "2022-06-29T13:17:38.865900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simple Regression model\n",
    "n_train_samples, n_test_samples, n_features = 100, 100, 10\n",
    "theta = np.random.uniform(size=n_features)  # regression coefficients\n",
    "X = np.random.normal(\n",
    "    size=(n_train_samples + n_test_samples, n_features))  # observations\n",
    "xi = np.random.normal(size=n_train_samples + n_test_samples)  # noise\n",
    "y = X @ theta + xi  # target\n",
    "X_train, X_test, y_train, y_test = tts(X, y, train_size=n_train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92aedd",
   "metadata": {},
   "source": [
    "### Create instance of FeedForwardRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070605ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:39.482196Z",
     "start_time": "2022-06-29T13:17:39.479705Z"
    }
   },
   "outputs": [],
   "source": [
    "reg = FeedForwardRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dc7cce",
   "metadata": {},
   "source": [
    "### Fit training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1657a229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:42.807146Z",
     "start_time": "2022-06-29T13:17:40.299084Z"
    }
   },
   "outputs": [],
   "source": [
    "reg = reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3834f97e",
   "metadata": {},
   "source": [
    "### Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16109379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:42.812563Z",
     "start_time": "2022-06-29T13:17:42.808568Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d39ad3",
   "metadata": {},
   "source": [
    "### Evaluate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd7ccb66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:42.819393Z",
     "start_time": "2022-06-29T13:17:42.813922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4402747646022337 0.4402747646022337\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, y_pred), reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863cc37e",
   "metadata": {},
   "source": [
    "### Clean up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1599f6a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:42.824588Z",
     "start_time": "2022-06-29T13:17:42.821940Z"
    }
   },
   "outputs": [],
   "source": [
    "reg.delete_model_weights()  # else gpu memory leaks\n",
    "del reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2998e9ae",
   "metadata": {},
   "source": [
    "## Same for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc5fe0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:43.663654Z",
     "start_time": "2022-06-29T13:17:42.826256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76 0.76 0.76 0.76\n"
     ]
    }
   ],
   "source": [
    "# Simple logistic model\n",
    "n_train_samples, n_test_samples, n_features = 100, 100, 10\n",
    "theta = np.random.uniform(size=n_features)\n",
    "X = np.random.normal(size=(n_train_samples + n_test_samples, n_features))\n",
    "xi = np.random.normal(size=n_train_samples + n_test_samples)\n",
    "y = (logistic_func(X @ theta + xi) > 0.5).astype(int)\n",
    "X_train, X_test, y_train, y_test = tts(X, y, train_size=n_train_samples)\n",
    "\n",
    "# Learning\n",
    "clf = FeedForwardClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "# y_proba = logistic_func(y_decision)\n",
    "y_decision = clf.decision_function(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred),\n",
    "      accuracy_score(y_test, (y_proba > 0.5).astype(float)),\n",
    "      accuracy_score(y_test, (y_decision > 0.).astype(float)),\n",
    "      clf.score(X_test, y_test))\n",
    "clf.delete_model_weights()  # else gpu memory leaks\n",
    "del clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad00ac",
   "metadata": {},
   "source": [
    "## Same for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18e3c78f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:44.466966Z",
     "start_time": "2022-06-29T13:17:43.664739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61 0.61 0.61 0.61\n"
     ]
    }
   ],
   "source": [
    "# Simple hardmax model\n",
    "n_train_samples, n_test_samples, n_features, n_classes = 100, 100, 10, 3\n",
    "theta = np.random.uniform(size=(n_features, n_classes))\n",
    "X = np.random.normal(size=(n_train_samples + n_test_samples, n_features))\n",
    "xi = np.random.normal(size=(n_train_samples + n_test_samples, n_classes))\n",
    "y = np.argmax(X @ theta + xi, axis=1)\n",
    "X_train, X_test, y_train, y_test = tts(X, y, train_size=n_train_samples)\n",
    "\n",
    "# Learning\n",
    "clf = FeedForwardClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)\n",
    "y_decision = clf.decision_function(X_test)  # y_proba = softmax(y_decision)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred),\n",
    "      accuracy_score(y_test, np.argmax(y_proba, axis=1)),\n",
    "      accuracy_score(y_test, np.argmax(y_decision, axis=1)),\n",
    "      clf.score(X_test, y_test))\n",
    "clf.delete_model_weights()  # else gpu memory leaks\n",
    "del clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b30cae",
   "metadata": {},
   "source": [
    "# Compare with Random Forests on a real-world dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89eebd50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:44.493128Z",
     "start_time": "2022-06-29T13:17:44.468083Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor as RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5323b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:44.496287Z",
     "start_time": "2022-06-29T13:17:44.494171Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb75d77",
   "metadata": {},
   "source": [
    "### Load California Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4e09b72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:44.510140Z",
     "start_time": "2022-06-29T13:17:44.497802Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X, y = StandardScaler().fit_transform(X), (y - y.mean()) / \\\n",
    "    y.std()  # standardize data\n",
    "train_samples_ratio = 0.8\n",
    "X_train, X_test, y_train, y_test = tts(\n",
    "    X, y, train_size=train_samples_ratio, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840c0ef0",
   "metadata": {},
   "source": [
    "### Train and evaluate a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb07b50e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:52.872807Z",
     "start_time": "2022-06-29T13:17:44.511418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF R2-score : 0.7982270387164677\n"
     ]
    }
   ],
   "source": [
    "reg = RF(random_state=seed)\n",
    "reg.fit(X_train, y_train)\n",
    "print(\"RF\", \"R2-score :\", reg.score(X_test, y_test))\n",
    "del reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7d395",
   "metadata": {},
   "source": [
    "### Train and evaluate a FFNN with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44251209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:53.128974Z",
     "start_time": "2022-06-29T13:17:52.873920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFNN R2-score : 0.2189434908152278\n"
     ]
    }
   ],
   "source": [
    "reg = FeedForwardRegressor(random_state=seed)\n",
    "reg.fit(X_train, y_train)\n",
    "print(\"FFNN\", \"R2-score :\", reg.score(X_test, y_test))\n",
    "reg.delete_model_weights()  # else gpu memory leaks\n",
    "del reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca309879",
   "metadata": {},
   "source": [
    "# Try other architectures and hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f6c2b5",
   "metadata": {},
   "source": [
    "### Use dictionnaries of parameters provided in parameters_examples.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "209eaecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:53.138540Z",
     "start_time": "2022-06-29T13:17:53.130075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp : {'lr_scheduler': 'OneCycleLR', 'lr_scheduler_params': {'max_lr': 0.01, 'total_steps': 200}, 'max_iter': 200, 'learning_rate': 0.001, 'hidden_nn': <class 'architectures.DenseLayers'>, 'hidden_params': {'width': 512, 'depth': 2, 'dropout': 0.2, 'batch_norm': True}} \n",
      "\n",
      "glu : {'lr_scheduler': 'OneCycleLR', 'lr_scheduler_params': {'max_lr': 0.01, 'total_steps': 500}, 'max_iter': 500, 'learning_rate': 0.001, 'hidden_nn': <class 'architectures.GLULayers'>, 'hidden_params': {'width': 512, 'depth': 3, 'dropout': 0.2, 'batch_norm': True}} \n",
      "\n",
      "snn : {'lr_scheduler': 'OneCycleLR', 'lr_scheduler_params': {'max_lr': 0.01, 'total_steps': 500}, 'max_iter': 500, 'learning_rate': 0.001, 'hidden_nn': <class 'architectures.DenseLayers'>, 'hidden_params': {'width': 512, 'depth': 2, 'activation': 'SELU', 'initializer_params': {'gain_type': 'linear'}}} \n",
      "\n",
      "mlpbatch : {'lr_scheduler': 'OneCycleLR', 'lr_scheduler_params': {'max_lr': 0.01, 'total_steps': 200}, 'max_iter': 200, 'epochs': True, 'max_runtime': 3600, 'learning_rate': 0.001, 'hidden_nn': <class 'architectures.DenseLayers'>, 'hidden_params': {'width': 512, 'depth': 2, 'dropout': 0.2, 'batch_norm': True}}\n"
     ]
    }
   ],
   "source": [
    "# see parameters_examples.py for details and other examples\n",
    "from parameters_examples import mlp, glu, snn, mlpbatch\n",
    "print(\"mlp\", \":\", mlp, \"\\n\")\n",
    "print(\"glu\", \":\", glu, \"\\n\")\n",
    "print(\"snn\", \":\", snn, \"\\n\")\n",
    "print(\"mlpbatch\", \":\", mlpbatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b1d57",
   "metadata": {},
   "source": [
    "### Pick one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3041821b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:53.142684Z",
     "start_time": "2022-06-29T13:17:53.140195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr_scheduler': 'OneCycleLR', 'lr_scheduler_params': {'max_lr': 0.01, 'total_steps': 200}, 'max_iter': 200, 'epochs': True, 'max_runtime': 3600, 'learning_rate': 0.001, 'hidden_nn': <class 'architectures.DenseLayers'>, 'hidden_params': {'width': 512, 'depth': 2, 'dropout': 0.2, 'batch_norm': True}}\n"
     ]
    }
   ],
   "source": [
    "# mlpbatch is more appropriate for medium to large datasets, see parameters_examples.py for details\n",
    "settings = \"mlpbatch\"\n",
    "kwargs = eval(settings)\n",
    "print(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc7c8f0",
   "metadata": {},
   "source": [
    "### Add data-specific infos (number of features, number of neurons on output layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c2291f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:53.146297Z",
     "start_time": "2022-06-29T13:17:53.143625Z"
    }
   },
   "outputs": [],
   "source": [
    "multiclass = False\n",
    "# number of neurons on output layer\n",
    "output = len(set(y_train)) if multiclass else 1\n",
    "kwargs[\"hidden_params\"].update(\n",
    "    {\"n_features\": X_train.shape[1], \"output\": output})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4b27f1",
   "metadata": {},
   "source": [
    "### Pass the parameters during the initialization of the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8028c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:53.149459Z",
     "start_time": "2022-06-29T13:17:53.147351Z"
    }
   },
   "outputs": [],
   "source": [
    "reg = FeedForwardRegressor(random_state=seed, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6451b",
   "metadata": {},
   "source": [
    "### Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594e61c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:17:55.778268Z",
     "start_time": "2022-06-29T13:17:53.150529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlpbatch R2-score : 0.8074418350336218\n"
     ]
    }
   ],
   "source": [
    "reg.fit(X_train, y_train)\n",
    "print(settings, \"R2-score :\", reg.score(X_test, y_test))\n",
    "reg.delete_model_weights()  # else gpu memory leaks\n",
    "del reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1336f0",
   "metadata": {},
   "source": [
    "# Perform meta-learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2827dec",
   "metadata": {},
   "source": [
    "### Train n = 10 models with different seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6f62d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:18:21.720624Z",
     "start_time": "2022-06-29T13:17:55.779412Z"
    }
   },
   "outputs": [],
   "source": [
    "n_learners = 10\n",
    "\n",
    "settings = \"mlpbatch\"\n",
    "kwargs = eval(settings)\n",
    "multiclass = False\n",
    "# number of neurons on output layer\n",
    "output = len(set(y_train)) if multiclass else 1\n",
    "kwargs[\"hidden_params\"].update(\n",
    "    {\"n_features\": X_train.shape[1], \"output\": output})\n",
    "\n",
    "predictions = np.zeros((n_learners, len(X_test)))\n",
    "records = {}\n",
    "for i in range(n_learners):\n",
    "    reg = FeedForwardRegressor(random_state=i, **kwargs)\n",
    "    reg.fit(X_train, y_train)\n",
    "    records[i] = reg.record\n",
    "    predictions[i] = reg.predict(X_test).reshape(-1)\n",
    "    reg.delete_model_weights()  # else gpu memory leaks\n",
    "    del reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ebc905",
   "metadata": {},
   "source": [
    "### Perform model ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b85a63a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:18:21.724808Z",
     "start_time": "2022-06-29T13:18:21.721635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble R2-score : 0.8082622719159248\n"
     ]
    }
   ],
   "source": [
    "ensemble_prediction = predictions.mean(axis=0)\n",
    "print(\"Ensemble\", \"R2-score :\", r2_score(y_test, ensemble_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d12cf",
   "metadata": {},
   "source": [
    "### Perform model selection (seed picking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4ff833a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:18:21.731009Z",
     "start_time": "2022-06-29T13:18:21.725956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection R2-score : 0.8014619989945647\n"
     ]
    }
   ],
   "source": [
    "best_seed = np.argmax([np.max(records[i][\"validation\"])\n",
    "                      for i in range(n_learners)])\n",
    "selected_prediction = predictions[best_seed]\n",
    "print(\"Selection\", \"R2-score :\", r2_score(y_test, selected_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef766877",
   "metadata": {},
   "source": [
    "# Use your own architecture on a dataset of tensor observations (eg: MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec4822e",
   "metadata": {},
   "source": [
    "### Define a pytorch module\n",
    "You can take inspiration from the architectures.py file. Here we will just copy [the pytorch example.](https://github.com/pytorch/examples/blob/master/mnist/main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5eb28e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:18:21.739419Z",
     "start_time": "2022-06-29T13:18:21.732465Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "if importlib.util.find_spec('torch.cuda'):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "\n",
    "class BasicConvNet(torch.nn.Module):\n",
    "    def __init__(self, device=device):\n",
    "        super(BasicConvNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3, 1, device=device)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1, device=device)\n",
    "        self.dropout1 = torch.nn.Dropout(0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(9216, 128, device=device)\n",
    "        self.fc2 = torch.nn.Linear(128, 10, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74941ee",
   "metadata": {},
   "source": [
    "### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0abba913",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:18:35.108868Z",
     "start_time": "2022-06-29T13:18:21.740470Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "train_samples_ratio = 0.8\n",
    "X_train, X_test, y_train, y_test = tts(\n",
    "    X, y, train_size=train_samples_ratio, stratify=y)\n",
    "X_train, X_test = X_train.reshape(\n",
    "    (-1, 1, 28, 28)), X_test.reshape((-1, 1, 28, 28))  # reshape as a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb9fc7",
   "metadata": {},
   "source": [
    "### Pick training hyper-parameters\n",
    "We will just copy [the pytorch example.](https://github.com/pytorch/examples/blob/master/mnist/main.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edcded5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:18:35.113410Z",
     "start_time": "2022-06-29T13:18:35.110196Z"
    }
   },
   "outputs": [],
   "source": [
    "kwargs = {\"optimizer\": \"Adadelta\",\n",
    "          \"validation_fraction\": False,\n",
    "          \"early_stopping_criterion\": False,\n",
    "          \"learning_rate\": 1.0,\n",
    "          \"optimizer_params\": {},\n",
    "          \"lr_scheduler\": \"StepLR\",\n",
    "          \"lr_scheduler_params\": {\"step_size\": 1, \"gamma\": 0.7},\n",
    "          \"batch_size\": 64,\n",
    "          \"max_iter\": 14 * int(len(y_train)/64),  # 14 epochs with batchsize 64\n",
    "          \"hidden_nn\": BasicConvNet,\n",
    "          \"hidden_params\": {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e0524",
   "metadata": {},
   "source": [
    "### Fit, predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ae5815d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:19:25.680775Z",
     "start_time": "2022-06-29T13:18:35.116266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9893571428571428\n"
     ]
    }
   ],
   "source": [
    "clf = FeedForwardClassifier(**kwargs)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "clf.delete_model_weights()  # else gpu memory leaks\n",
    "del clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dafd650",
   "metadata": {},
   "source": [
    "# Play with all the training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aecc2125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:19:25.686585Z",
     "start_time": "2022-06-29T13:19:25.681797Z"
    }
   },
   "outputs": [],
   "source": [
    "# Exhaustive parameter list:\n",
    "if False:\n",
    "    if False:\n",
    "        # architecture of hidden layers, torch.nn.Module (if False, uses default mlp architecture).\n",
    "        hidden_nn,\n",
    "        hidden_params,  # hyper_parameters for hidden_nn initialization\n",
    "\n",
    "        # learning parameters\n",
    "        default_loss_function,  # set by the subclass\n",
    "        optimizer,  # a torch optimizer, str\n",
    "        learning_rate,  # float\n",
    "        optimizer_params,  # except learning rate, dict\n",
    "        lr_scheduler,  # a torch optimizer.lr_scheduler, str\n",
    "        lr_scheduler_params,  # dict\n",
    "        batch_size,  # if None or False: full batch, if int number of samples, if float share of samples\n",
    "\n",
    "        # convergence parameters\n",
    "        max_iter,  # iterations, not epochs (epochs = max_iter/batch_size), int\n",
    "        epochs,  # max_iter => max_iter * train_size / batch_size, bool\n",
    "        max_runtime,  # unprecise, float or int\n",
    "        # if None or False: no validation, if int number of samples, if float share of samples\n",
    "        validation_fraction,\n",
    "        should_stratify,  # validation split strategy, bool\n",
    "        early_stopping_criterion,  # either \"loss\" or \"validation\", str\n",
    "        convergence_tol,  # if None or False: always max_iter, else float\n",
    "        divergence_tol,  # if None or False: always max_iter, else float\n",
    "\n",
    "        # AdaCap Parameters\n",
    "        # Tikhonov operator specific parameters\n",
    "        adacap,\n",
    "        # if None or False: regular FFNN, if int or float lambda initial value, if \"max_variation\" or \"min_value\" grid-search\n",
    "        closeform_parameter_init,\n",
    "        closeform_intercept,  # add unitary feature to covar matrix, bool\n",
    "\n",
    "        # MuddlingLabelRegularization specific parameters\n",
    "        n_permut,  # if int number of permutations, if None or False no permutations\n",
    "        permutation_scale,  # weight of permutation term added to the loss, float\n",
    "\n",
    "        # MLR additional regularization techniques\n",
    "        dithering_scale,  # if float dithering white noise standard-deviation, if None or False no gaussian dithering\n",
    "        # if float dithering structured noise standard-deviation, if None or False no structured noise dithering\n",
    "        target_rotation_scale,\n",
    "\n",
    "        # Target handling\n",
    "        # center target around mean (behaves differently for binary clf), bool\n",
    "        center_target,\n",
    "        rescale_target,  # divide target by std before fitting, bool\n",
    "        loss_imbalance,  # smaller weights on majority classes, bool\n",
    "\n",
    "        random_state,  # scikit-learn random state, will also set torch generator using a different seed\n",
    "        # delete validation samples, optimizer and lr scheduler after training\n",
    "        release_train_memory,\n",
    "        # repository in which tempory models will be saved (see PATH and REP)\n",
    "        save_repository,\n",
    "        verbose  # if False mute, if True print at each iteration, if int print if iter%verbose == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42cc11b",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "856df6e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:19:25.701669Z",
     "start_time": "2022-06-29T13:19:25.687545Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X, y = StandardScaler().fit_transform(X), (y - y.mean()) / \\\n",
    "    y.std()  # standardize data\n",
    "train_samples_ratio = 0.8\n",
    "X_train, X_test, y_train, y_test = tts(X, y, train_size=train_samples_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4010521c",
   "metadata": {},
   "source": [
    "### Print metrics values every 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e1a0a65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:19:25.957040Z",
     "start_time": "2022-06-29T13:19:25.702764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     iter |     loss |     time | validati |\n",
      "|        0 | 2.04e+00 | 5.81e-03 | -9.75e-01 |\n",
      "|       10 | 1.58e+00 | 5.98e-03 | 3.32e-01 |\n",
      "|       20 | 1.99e+00 | 5.31e-03 | 1.67e-01 |\n",
      "|       30 | 9.13e-01 | 5.15e-03 | 5.98e-01 |\n",
      "|       40 | 8.12e-01 | 2.98e-03 | 6.53e-01 |\n",
      "|       50 | 9.35e-01 | 3.30e-03 | 6.66e-01 |\n"
     ]
    }
   ],
   "source": [
    "reg = FeedForwardRegressor(release_train_memory=False, verbose=10)\n",
    "reg = reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a178fa66",
   "metadata": {},
   "source": [
    "### Save learning dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "535f89d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:19:25.960891Z",
     "start_time": "2022-06-29T13:19:25.958218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'time', 'validation'])\n"
     ]
    }
   ],
   "source": [
    "record = reg.record\n",
    "print(record.keys())  # you can then plot these with matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d32070b",
   "metadata": {},
   "source": [
    "### Hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "709ff0da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:19:25.964566Z",
     "start_time": "2022-06-29T13:19:25.961962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DefaultDenseLayers(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.2, inplace=False)\n",
      "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = reg.hidden_layers\n",
    "print(hidden_layers)\n",
    "del hidden_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500b9312",
   "metadata": {},
   "source": [
    "### Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b8fb43a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:19:25.968935Z",
     "start_time": "2022-06-29T13:19:25.965843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    base_momentum: 0.85\n",
      "    betas: (0.949798714699762, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.0004\n",
      "    lr: 2.0168449509684565e-05\n",
      "    max_lr: 0.01\n",
      "    max_momentum: 0.95\n",
      "    min_lr: 4e-08\n",
      "    weight_decay: 0\n",
      ")\n",
      "<torch.optim.lr_scheduler.OneCycleLR object at 0x7fcce01e95b0>\n"
     ]
    }
   ],
   "source": [
    "optimizer = reg.optimizer_instance\n",
    "print(optimizer)\n",
    "if not reg.cst_lr:\n",
    "    lr_scheduler = reg.lr_scheduler_instance\n",
    "    print(lr_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63157450",
   "metadata": {},
   "source": [
    "### Re-use a network copy elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "521f716c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:19:25.978595Z",
     "start_time": "2022-06-29T13:19:25.970210Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# this file will be deleted with reg.delete_model_weights()\n",
    "storage_path = reg.save_repository + reg.PATH\n",
    "network_copy = torch.load(storage_path)\n",
    "new_storage_path = \"./saved_model.pt\"\n",
    "torch.save(network_copy, new_storage_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85b721c",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b576715c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:19:25.983783Z",
     "start_time": "2022-06-29T13:19:25.980079Z"
    }
   },
   "outputs": [],
   "source": [
    "reg._release_train_memory()\n",
    "reg.delete_model_weights()  # else gpu memory leaks\n",
    "del reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "391f860a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-29T13:19:25.986896Z",
     "start_time": "2022-06-29T13:19:25.984896Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove(new_storage_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a33709",
   "metadata": {},
   "source": [
    "# Remarks on batch-learning.\n",
    "There are two ways in which the default behavior of the FeedForwardNeuralNetwork differs from the standard approach. Note however that in both cases changing parameters is enough to fall back to the most classical setting. \n",
    "\n",
    "- The FeedForwardNeuralNetwork class can perform batch-learning but by default, it tries to avoid doing so (which is most often the correct strategy for small tabular datasets). However, to avoid GPU memory errors, some caps on the maximum size of weights and activations matrices are hard-coded: the width and height is at most 4096. This means that even if the parameter \"batch_size\" is equal to False, batch-learning will be used if the training set (substracting the validation set if any) is larger than 4096. Mini-batches of size smaller than 4096 can still be used by setting the \"batch_size\" to an int.\\\\\n",
    "\n",
    "\n",
    "- The cap on the maximum number of iterations corresponds by default to the maximum number of gradient updates, not epochs. This enforces a soft constraint on the maximum training time with respect to the training set size, as at most, the gradients will be computed for max_iter times 4096 observations. It is possible nonetheless to set the maximum number of epochs instead, by setting the parameter \"epochs\" as True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166f24e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FFNN_demo]",
   "language": "python",
   "name": "conda-env-FFNN_demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
